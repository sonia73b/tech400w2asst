{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJXL9ZWUpKsichyHttVhFf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonia73b/tech400asst/blob/main/W3TECH400.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtCinfqkALHJ",
        "outputId": "aab4b5a2-8a8e-472b-cfe1-c3d5a1680b31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q scikit-learn pandas\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "9zWzexg-ffLd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DOCS_FOLDER = \"/content/drive/MyDrive/TECH400TXTFILES\"\n",
        "\n",
        "# Base folder for queries + results\n",
        "BASE_FOLDER = \"/content/TECH400W3ASST\"\n",
        "\n",
        "os.makedirs(DOCS_FOLDER, exist_ok=True)\n",
        "os.makedirs(BASE_FOLDER, exist_ok=True)\n",
        "\n",
        "# Output files\n",
        "QUERIES_FILE       = os.path.join(BASE_FOLDER, \"queries.txt\")\n",
        "QUERY_RESULTS_FILE = os.path.join(BASE_FOLDER, \"query_results.txt\")\n",
        "QUERY_RESULTS_CSV  = os.path.join(BASE_FOLDER, \"query_results_tfidf.csv\")\n",
        "DOC_SIM_TXT        = os.path.join(BASE_FOLDER, \"doc_doc_similarity.txt\")\n",
        "DOC_SIM_CSV        = os.path.join(BASE_FOLDER, \"doc_doc_similarity.csv\")"
      ],
      "metadata": {
        "id": "0Q2Bd9tbQEio"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queries = [\n",
        "    \"AI OR artificial\",\n",
        "    \"oil AND surplus\",\n",
        "    \"OPEC OR quota\",\n",
        "    \"disease AND outbreak\",\n",
        "    \"space AND mission\",\n",
        "    \"education AND policy\",\n",
        "    \"markets OR investors\",\n",
        "    \"football OR tennis\",\n",
        "    \"AI AND NOT oil\",\n",
        "    \"disease AND NOT Marburg\"\n",
        "]\n",
        "\n",
        "with open(QUERIES_FILE, \"w\", encoding=\"utf-8\") as f:\n",
        "    for q in queries:\n",
        "        f.write(q + \"\\n\")\n",
        "\n",
        "print(\"Saved queries to:\", QUERIES_FILE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQzRVZb5fogX",
        "outputId": "edcf66d4-f30c-47b9-c102-d5c8766402a8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved queries to: /content/TECH400W3ASST/queries.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_documents(docs_folder):\n",
        "    \"\"\"\n",
        "    Reads all .txt files from docs_folder.\n",
        "    Returns:\n",
        "        filenames: ['file1.txt', 'file2.txt', ...]\n",
        "        texts:     ['full text of file1', 'full text of file2', ...]\n",
        "    \"\"\"\n",
        "    file_paths = sorted(glob.glob(os.path.join(docs_folder, \"*.txt\")))\n",
        "    filenames = [os.path.basename(p) for p in file_paths]\n",
        "    texts = []\n",
        "    for p in file_paths:\n",
        "        with open(p, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            texts.append(f.read())\n",
        "    return filenames, texts\n",
        "\n",
        "def load_queries(queries_file):\n",
        "    \"\"\"\n",
        "    Reads queries from queries.txt (one per line).\n",
        "    \"\"\"\n",
        "    with open(queries_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        lines = [line.strip() for line in f.readlines()]\n",
        "    return [q for q in lines if q]\n",
        "\n",
        "filenames, doc_texts = load_documents(DOCS_FOLDER)\n",
        "query_texts = load_queries(QUERIES_FILE)\n",
        "\n",
        "print(\"Documents loaded:\", filenames)\n",
        "print(\"Queries loaded:\", query_texts)\n",
        "\n",
        "\n",
        "# Safety check\n",
        "if len(doc_texts) == 0:\n",
        "    raise RuntimeError(\"No .txt files found in DOCS_FOLDER. Check path and files.\")\n",
        "if len(query_texts) == 0:\n",
        "    raise RuntimeError(\"No queries loaded from queries.txt. Check QUERIES_FILE.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2vKHGpUfsDS",
        "outputId": "4cd7b5dc-fe30-469d-e1c3-4fffc3befa95"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documents loaded: ['Analysts_ai.txt', 'Capital_expenditure_for_AI.txt', 'Global_oil_markets_supply.txt', 'Health_authorities_in_Ethiopia.txt', 'NASA’s_ESCAPADE_mission.txt', 'Oil_prices_climbed_this_week.txt', 'UNESCO_Education_policy.txt', 'WHO_Disease_outbreak.txt']\n",
            "Queries loaded: ['AI OR artificial', 'oil AND surplus', 'OPEC OR quota', 'disease AND outbreak', 'space AND mission', 'education AND policy', 'markets OR investors', 'football OR tennis', 'AI AND NOT oil', 'disease AND NOT Marburg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_for_fit = doc_texts + query_texts\n",
        "\n",
        "vectorizer = TfidfVectorizer(\n",
        "    lowercase=True,\n",
        "    token_pattern=r\"[A-Za-z0-9\\-]+\"\n",
        ")\n",
        "\n",
        "X = vectorizer.fit_transform(corpus_for_fit)\n",
        "\n",
        "num_docs = len(doc_texts)\n",
        "num_queries = len(query_texts)\n",
        "\n",
        "# First part: documents, second part: queries\n",
        "doc_matrix   = X[:num_docs, :]\n",
        "query_matrix = X[num_docs:, :]\n",
        "\n",
        "print(\"TF-IDF matrix shape (docs):\", doc_matrix.shape)\n",
        "print(\"TF-IDF matrix shape (queries):\", query_matrix.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGA1SyRFfwsM",
        "outputId": "c598879f-13f7-4fec-ee45-f6591c6d6f0e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF matrix shape (docs): (8, 754)\n",
            "TF-IDF matrix shape (queries): (10, 754)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "QxD = cosine_similarity(query_matrix, doc_matrix)  # [Q x D]\n",
        "\n",
        "rows = []\n",
        "for qi, q in enumerate(query_texts):\n",
        "    sims = QxD[qi]  # similarities of this query to all docs\n",
        "    # rank documents by similarity (highest first)\n",
        "    ranking = sorted(zip(filenames, sims), key=lambda t: t[1], reverse=True)\n",
        "    for rank, (fname, score) in enumerate(ranking, start=1):\n",
        "        rows.append({\n",
        "            \"query\": q,\n",
        "            \"doc_rank\": rank,\n",
        "            \"document\": fname,\n",
        "            \"cosine_similarity\": round(float(score), 4)\n",
        "        })\n",
        "\n",
        "results_df = pd.DataFrame(rows)\n",
        "results_df.to_csv(QUERY_RESULTS_CSV, index=False, encoding=\"utf-8\")\n",
        "print(\"Saved ranked query–document results to:\", QUERY_RESULTS_CSV)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRxt981Df0Ex",
        "outputId": "8d539ec1-5f82-4ea8-fa07-554fbeff0636"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved ranked query–document results to: /content/TECH400W3ASST/query_results_tfidf.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(QUERY_RESULTS_FILE, \"w\", encoding=\"utf-8\") as f:\n",
        "    for q in results_df[\"query\"].unique():\n",
        "        f.write(\"====================================\\n\")\n",
        "        f.write(f\"QUERY: {q}\\n\")\n",
        "        f.write(\"====================================\\n\")\n",
        "        sub = results_df[results_df[\"query\"] == q].sort_values(\"doc_rank\")\n",
        "        for _, row in sub.iterrows():\n",
        "            f.write(\n",
        "                f\"Rank {int(row['doc_rank'])}: \"\n",
        "                f\"{row['document']} \"\n",
        "                f\"(cosine={row['cosine_similarity']})\\n\"\n",
        "            )\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "print(\"Saved human-readable query results to:\", QUERY_RESULTS_FILE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tioFB63Vf1ed",
        "outputId": "c4860d00-bfdb-45de-eb25-e59544e88630"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved human-readable query results to: /content/TECH400W3ASST/query_results.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DxD = cosine_similarity(doc_matrix, doc_matrix)  # [D x D]\n",
        "\n",
        "doc_sim_df = pd.DataFrame(DxD, index=filenames, columns=filenames)\n",
        "\n",
        "# Save as CSV\n",
        "doc_sim_df.to_csv(DOC_SIM_CSV, encoding=\"utf-8\")\n",
        "print(\"Saved document–document similarity CSV to:\", DOC_SIM_CSV)\n",
        "\n",
        "# Save as TXT\n",
        "with open(DOC_SIM_TXT, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"Document–Document Cosine Similarity (TF-IDF Vector Space Model)\\n\\n\")\n",
        "    f.write(doc_sim_df.to_string())\n",
        "\n",
        "print(\"Saved document–document similarity TXT to:\", DOC_SIM_TXT)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C61YGVYUf50-",
        "outputId": "df41f0aa-1ecf-48c4-b531-fd5776bb1ae9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved document–document similarity CSV to: /content/TECH400W3ASST/doc_doc_similarity.csv\n",
            "Saved document–document similarity TXT to: /content/TECH400W3ASST/doc_doc_similarity.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top3_rows = []\n",
        "\n",
        "for q in results_df[\"query\"].unique():\n",
        "    sub = results_df[results_df[\"query\"] == q].sort_values(\"doc_rank\").head(3)\n",
        "\n",
        "    for _, row in sub.iterrows():\n",
        "        top3_rows.append({\n",
        "            \"Query\": q,\n",
        "            \"Rank\": int(row[\"doc_rank\"]),\n",
        "            \"Document\": row[\"document\"],\n",
        "            \"Cosine Similarity\": float(row[\"cosine_similarity\"])\n",
        "        })\n",
        "\n",
        "top3_df = pd.DataFrame(top3_rows)\n",
        "\n",
        "print(\"\\nTop-3 documents per query (preview):\")\n",
        "print(top3_df.to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIzXqCIIf8UH",
        "outputId": "d3292714-cdb5-4dae-ce23-9be6d1b6833b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top-3 documents per query (preview):\n",
            "                  Query  Rank                           Document  Cosine Similarity\n",
            "       AI OR artificial     1                    Analysts_ai.txt             0.1218\n",
            "       AI OR artificial     2     Capital_expenditure_for_AI.txt             0.0824\n",
            "       AI OR artificial     3        UNESCO_Education_policy.txt             0.0265\n",
            "        oil AND surplus     1      Global_oil_markets_supply.txt             0.1690\n",
            "        oil AND surplus     2   Oil_prices_climbed_this_week.txt             0.1025\n",
            "        oil AND surplus     3 Health_authorities_in_Ethiopia.txt             0.0641\n",
            "          OPEC OR quota     1   Oil_prices_climbed_this_week.txt             0.0398\n",
            "          OPEC OR quota     2        UNESCO_Education_policy.txt             0.0233\n",
            "          OPEC OR quota     3     Capital_expenditure_for_AI.txt             0.0194\n",
            "   disease AND outbreak     1           WHO_Disease_outbreak.txt             0.1733\n",
            "   disease AND outbreak     2 Health_authorities_in_Ethiopia.txt             0.1049\n",
            "   disease AND outbreak     3        UNESCO_Education_policy.txt             0.0555\n",
            "      space AND mission     1        NASA’s_ESCAPADE_mission.txt             0.2147\n",
            "      space AND mission     2 Health_authorities_in_Ethiopia.txt             0.0591\n",
            "      space AND mission     3        UNESCO_Education_policy.txt             0.0504\n",
            "   education AND policy     1        UNESCO_Education_policy.txt             0.3667\n",
            "   education AND policy     2   Oil_prices_climbed_this_week.txt             0.0736\n",
            "   education AND policy     3 Health_authorities_in_Ethiopia.txt             0.0619\n",
            "   markets OR investors     1     Capital_expenditure_for_AI.txt             0.0566\n",
            "   markets OR investors     2      Global_oil_markets_supply.txt             0.0444\n",
            "   markets OR investors     3                    Analysts_ai.txt             0.0316\n",
            "     football OR tennis     1        UNESCO_Education_policy.txt             0.0221\n",
            "     football OR tennis     2     Capital_expenditure_for_AI.txt             0.0185\n",
            "     football OR tennis     3                    Analysts_ai.txt             0.0000\n",
            "         AI AND NOT oil     1   Oil_prices_climbed_this_week.txt             0.1265\n",
            "         AI AND NOT oil     2                    Analysts_ai.txt             0.1223\n",
            "         AI AND NOT oil     3     Capital_expenditure_for_AI.txt             0.0986\n",
            "disease AND NOT Marburg     1           WHO_Disease_outbreak.txt             0.1037\n",
            "disease AND NOT Marburg     2 Health_authorities_in_Ethiopia.txt             0.0918\n",
            "disease AND NOT Marburg     3   Oil_prices_climbed_this_week.txt             0.0621\n"
          ]
        }
      ]
    }
  ]
}